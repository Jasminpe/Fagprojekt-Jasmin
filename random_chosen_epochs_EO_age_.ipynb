{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "891c6a6f",
   "metadata": {},
   "source": [
    "# Age prediction using the top 60 EC epochs found in del2_2 (calculating alpha power)\n",
    "### Predicting age groups with increments of 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323028b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# ------------ LOAD DATA ------------\n",
    "with open(\"top_epochs_per_subject.pkl\", \"rb\") as f:\n",
    "    top_epochs_per_subject = pickle.load(f)\n",
    "\n",
    "# Ensure keys are strings and trimmed\n",
    "top_epochs_per_subject = {str(k).strip(): v for k, v in top_epochs_per_subject.items()}\n",
    "\n",
    "metadata = pd.read_csv(\"metadata_time_filtered.csv\")\n",
    "metadata[\"subject_id\"] = metadata[\"subject_id\"].astype(str).str.strip()\n",
    "\n",
    "# Filter out subjects 90 years or older\n",
    "metadata = metadata[metadata[\"age\"] < 90]\n",
    "\n",
    "# Keep only subjects present in both metadata and epochs dictionary\n",
    "all_subjects = [s for s in top_epochs_per_subject.keys() if s in metadata[\"subject_id\"].values]\n",
    "\n",
    "random.seed(42)\n",
    "test_subjects = random.sample(all_subjects, 500)\n",
    "train_subjects = [s for s in all_subjects if s not in test_subjects]\n",
    "\n",
    "# ------------ DEFINE AGE GROUP LABELS ------------\n",
    "def assign_age_group(age):\n",
    "    return age // 10  # Groups by decades: 0–9 → 0, 10–19 →1, etc.\n",
    "\n",
    "metadata[\"age_group\"] = metadata[\"age\"].apply(assign_age_group)\n",
    "metadata = metadata[metadata[\"subject_id\"].isin(all_subjects)]\n",
    "\n",
    "# ------------ FEATURE EXTRACTION ------------\n",
    "def extract_combined_features(subject_id, epoch_indices, set_folder):\n",
    "    path = f\"{set_folder}/{subject_id}_epoched.set\"\n",
    "    epochs = mne.io.read_epochs_eeglab(path, verbose='ERROR')\n",
    "    data = epochs.get_data()[epoch_indices]\n",
    "    sfreq = epochs.info[\"sfreq\"]\n",
    "\n",
    "    bands = {\n",
    "        \"delta\": (1, 4),\n",
    "        \"theta\": (4, 8),\n",
    "        \"alpha\": (8, 13),\n",
    "        \"beta\": (13, 30),\n",
    "    }\n",
    "    \n",
    "    band_powers = []\n",
    "    relative_powers = []\n",
    "\n",
    "    # Total PSD for 1-45 Hz (for relative power & slope)\n",
    "    total_psds, total_freqs = mne.time_frequency.psd_array_welch(\n",
    "        data, sfreq=sfreq, fmin=1, fmax=45, n_fft=128, verbose=False\n",
    "    )\n",
    "    total_power = total_psds.sum(axis=-1)  # shape: (epochs, channels)\n",
    "\n",
    "    # --- Spectral slope calculation ---\n",
    "    mean_psd = total_psds.mean(axis=(0,1))  # mean over epochs and channels\n",
    "    freqs_log = np.log10(total_freqs)\n",
    "    psd_log = np.log10(mean_psd)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(freqs_log.reshape(-1,1), psd_log)\n",
    "    spectral_slope = model.coef_[0]\n",
    "\n",
    "    # --- Alpha peak frequency ---\n",
    "    psds_alpha, freqs_alpha = mne.time_frequency.psd_array_welch(\n",
    "        data, sfreq=sfreq, fmin=8, fmax=13, n_fft=128, verbose=False\n",
    "    )\n",
    "    mean_alpha_psd = psds_alpha.mean(axis=(0,1))\n",
    "    alpha_peak_idx = mean_alpha_psd.argmax()\n",
    "    alpha_peak_freq = freqs_alpha[alpha_peak_idx]\n",
    "\n",
    "    # Compute band powers and relative powers\n",
    "    for band_name, (fmin, fmax) in bands.items():\n",
    "        psds_band, _ = mne.time_frequency.psd_array_welch(\n",
    "            data, sfreq=sfreq, fmin=fmin, fmax=fmax, n_fft=128, verbose=False\n",
    "        )\n",
    "        abs_power = psds_band.mean(axis=(0,2))  # mean over epochs and freq bins per channel\n",
    "        band_powers.extend(abs_power)\n",
    "        \n",
    "        rel_power = (psds_band.sum(axis=-1) / total_power).mean()\n",
    "        relative_powers.append(rel_power)\n",
    "    \n",
    "    features = np.concatenate([band_powers, relative_powers, [spectral_slope, alpha_peak_freq]])\n",
    "    return features\n",
    "\n",
    "# ------------ EXTRACT FEATURES FROM TRAIN SET ------------\n",
    "set_folder = \"G:/ChristianMusaeus/Preprocessed_setfiles\"  # <-- Update your path here!\n",
    "\n",
    "X, y, subject_ids = [], [], []\n",
    "\n",
    "for subj_id in train_subjects:\n",
    "    try:\n",
    "        epoch_inds = top_epochs_per_subject[subj_id]\n",
    "        features = extract_combined_features(subj_id, epoch_inds, set_folder)\n",
    "        age_group = metadata.loc[metadata[\"subject_id\"] == subj_id, \"age_group\"].values[0]\n",
    "        X.append(features)\n",
    "        y.append(age_group)\n",
    "        subject_ids.append(subj_id)\n",
    "    except Exception as e:\n",
    "        print(f\" Error processing {subj_id}: {e}\")\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# ------------ 5-FOLD CROSS VALIDATION ------------\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), start=1):\n",
    "    print(f\"\\n Fold {fold} running...\")\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    preds = model.predict(X_val_scaled)\n",
    "    acc = accuracy_score(y_val, preds)\n",
    "    accuracies.append(acc)\n",
    "    print(f\"Fold {fold} Accuracy: {acc:.3f}\")\n",
    "\n",
    "print(f\"\\n Mean CV Accuracy: {np.mean(accuracies):.3f}\")\n",
    "\n",
    "# ------------ FINAL MODEL TRAINING ------------\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "final_model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "final_model.fit(X_scaled, y)\n",
    "\n",
    "# ------------ TEST SET EVALUATION ------------\n",
    "X_test, y_test = [], []\n",
    "\n",
    "for subj_id in test_subjects:\n",
    "    try:\n",
    "        epoch_inds = top_epochs_per_subject[subj_id]\n",
    "        features = extract_combined_features(subj_id, epoch_inds, set_folder)\n",
    "        age_group = metadata.loc[metadata[\"subject_id\"] == subj_id, \"age_group\"].values[0]\n",
    "        X_test.append(features)\n",
    "        y_test.append(age_group)\n",
    "    except Exception as e:\n",
    "        print(f\" Error processing test subject {subj_id}: {e}\")\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "test_preds = final_model.predict(X_test_scaled)\n",
    "test_acc = accuracy_score(y_test, test_preds)\n",
    "print(f\"\\n Final Test Accuracy: {test_acc:.3f}\")\n",
    "print(classification_report(y_test, test_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f0ee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4179a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, test_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "disp.plot(ax=ax, cmap = 'Blues', colorbar = True)\n",
    "plt.title(\"Confusion Matrix for Test Set Predictions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8f1d34",
   "metadata": {},
   "source": [
    "# The same kind of classification, but instead using 60 radnmly chosen epochs from label_predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083420ff",
   "metadata": {},
   "source": [
    "### Extracting 60 random epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786bf040",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(\"label_predictions.csv\")  \n",
    "\n",
    "# Sample 60 epochs per subject (mixed EC and EO)\n",
    "random_epochs_per_subject = {}\n",
    "for subj_id, group in labels_df.groupby(\"Test subject ID\"):\n",
    "    if len(group) >= 60:\n",
    "        sampled = group.sample(n=60, random_state=13)\n",
    "        random_epochs_per_subject[subj_id] = sampled[\"Epoch number\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350ab240",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(random_epochs_per_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7881ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "metadata = pd.read_csv(\"metadata_time_filtered.csv\")\n",
    "metadata[\"subject_id\"] = metadata[\"subject_id\"].astype(str).str.strip()\n",
    "\n",
    "# Filter out subjects 90 or older\n",
    "metadata = metadata[metadata[\"age\"] < 90]\n",
    "\n",
    "random_epochs_per_subject = {str(k).strip(): v for k, v in random_epochs_per_subject.items()}\n",
    "\n",
    "# Keep only subjects present in both metadata and random_epochs_per_subject\n",
    "all_subjects_random = [s for s in random_epochs_per_subject.keys() if s in metadata[\"subject_id\"].values]\n",
    "print(len(all_subjects_random))\n",
    "\n",
    "random.seed(42)\n",
    "test_subjects_random = test_subjects\n",
    "train_subjects_random = [s for s in all_subjects_random if s not in test_subjects_random]\n",
    "\n",
    "# Define age groups\n",
    "def assign_age_group(age):\n",
    "    return age // 10  # decade groups\n",
    "\n",
    "metadata[\"age_group\"] = metadata[\"age\"].apply(assign_age_group)\n",
    "metadata = metadata[metadata[\"subject_id\"].isin(all_subjects_random)]\n",
    "\n",
    "# ------------ FEATURE EXTRACTION ------------\n",
    "def extract_combined_features_random(subject_id, epoch_indices, set_folder):\n",
    "    path = f\"{set_folder}/{subject_id}_epoched.set\"\n",
    "    epochs = mne.io.read_epochs_eeglab(path, verbose='ERROR')\n",
    "    data = epochs.get_data()[epoch_indices]\n",
    "    sfreq = epochs.info[\"sfreq\"]\n",
    "\n",
    "    bands = {\n",
    "        \"delta\": (1, 4),\n",
    "        \"theta\": (4, 8),\n",
    "        \"alpha\": (8, 13),\n",
    "        \"beta\": (13, 30),\n",
    "    }\n",
    "    \n",
    "    band_powers = []\n",
    "    relative_powers = []\n",
    "\n",
    "    # Total PSD for 1-45 Hz (for relative power & slope)\n",
    "    total_psds, total_freqs = mne.time_frequency.psd_array_welch(\n",
    "        data, sfreq=sfreq, fmin=1, fmax=45, n_fft=128, verbose=False\n",
    "    )\n",
    "    total_power = total_psds.sum(axis=-1)  # shape: (epochs, channels)\n",
    "\n",
    "    # Spectral slope calculation\n",
    "    mean_psd = total_psds.mean(axis=(0,1))  # mean over epochs and channels\n",
    "    freqs_log = np.log10(total_freqs)\n",
    "    psd_log = np.log10(mean_psd)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(freqs_log.reshape(-1,1), psd_log)\n",
    "    spectral_slope = model.coef_[0]\n",
    "\n",
    "    # Alpha peak frequency\n",
    "    psds_alpha, freqs_alpha = mne.time_frequency.psd_array_welch(\n",
    "        data, sfreq=sfreq, fmin=8, fmax=13, n_fft=128, verbose=False\n",
    "    )\n",
    "    mean_alpha_psd = psds_alpha.mean(axis=(0,1))\n",
    "    alpha_peak_idx = mean_alpha_psd.argmax()\n",
    "    alpha_peak_freq = freqs_alpha[alpha_peak_idx]\n",
    "\n",
    "    # Band powers & relative powers\n",
    "    for band_name, (fmin, fmax) in bands.items():\n",
    "        psds_band, _ = mne.time_frequency.psd_array_welch(\n",
    "            data, sfreq=sfreq, fmin=fmin, fmax=fmax, n_fft=128, verbose=False\n",
    "        )\n",
    "        abs_power = psds_band.mean(axis=(0,2))\n",
    "        band_powers.extend(abs_power)\n",
    "        \n",
    "        rel_power = (psds_band.sum(axis=-1) / total_power).mean()\n",
    "        relative_powers.append(rel_power)\n",
    "    \n",
    "    features = np.concatenate([band_powers, relative_powers, [spectral_slope, alpha_peak_freq]])\n",
    "    return features\n",
    "\n",
    "# ------------ EXTRACT FEATURES FROM TRAIN SET ------------\n",
    "set_folder = \"G:/ChristianMusaeus/Preprocessed_setfiles\"  # <-- Update your path here!\n",
    "\n",
    "X_random, y_random, subject_ids_random = [], [], []\n",
    "\n",
    "for subj_id in train_subjects_random:\n",
    "    try:\n",
    "        epoch_inds = random_epochs_per_subject[subj_id]\n",
    "        features = extract_combined_features_random(subj_id, epoch_inds, set_folder)\n",
    "        age_group = metadata.loc[metadata[\"subject_id\"] == subj_id, \"age_group\"].values[0]\n",
    "        X_random.append(features)\n",
    "        y_random.append(age_group)\n",
    "        subject_ids_random.append(subj_id)\n",
    "    except Exception as e:\n",
    "        print(f\" Error processing {subj_id}: {e}\")\n",
    "\n",
    "X_random = np.array(X_random)\n",
    "y_random = np.array(y_random)\n",
    "\n",
    "# ------------ 5-FOLD CROSS VALIDATION ------------\n",
    "skf_random = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies_random = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf_random.split(X_random, y_random), start=1):\n",
    "    print(f\"\\n Fold {fold} running...\")\n",
    "    X_train, X_val = X_random[train_idx], X_random[val_idx]\n",
    "    y_train, y_val = y_random[train_idx], y_random[val_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    model_random = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "    model_random.fit(X_train_scaled, y_train)\n",
    "\n",
    "    preds_random = model_random.predict(X_val_scaled)\n",
    "    acc = accuracy_score(y_val, preds_random)\n",
    "    accuracies_random.append(acc)\n",
    "    print(f\"Fold {fold} Accuracy: {acc:.3f}\")\n",
    "\n",
    "print(f\"\\n Mean CV Accuracy: {np.mean(accuracies_random):.3f}\")\n",
    "\n",
    "# ------------ FINAL MODEL TRAINING ------------\n",
    "scaler = StandardScaler()\n",
    "X_scaled_random = scaler.fit_transform(X_random)\n",
    "final_model_random = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "final_model_random.fit(X_scaled_random, y_random)\n",
    "\n",
    "# ------------ TEST SET EVALUATION ------------\n",
    "X_test_random, y_test_random = [], []\n",
    "\n",
    "for subj_id in test_subjects_random:\n",
    "    try:\n",
    "        epoch_inds = random_epochs_per_subject[subj_id]\n",
    "        features = extract_combined_features_random(subj_id, epoch_inds, set_folder)\n",
    "        age_group = metadata.loc[metadata[\"subject_id\"] == subj_id, \"age_group\"].values[0]\n",
    "        X_test_random.append(features)\n",
    "        y_test_random.append(age_group)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing test subject {subj_id}: {e}\")\n",
    "\n",
    "X_test_random = np.array(X_test_random)\n",
    "y_test_random = np.array(y_test_random)\n",
    "X_test_scaled_random = scaler.transform(X_test_random)\n",
    "\n",
    "test_preds_random = final_model_random.predict(X_test_scaled_random)\n",
    "test_acc_random = accuracy_score(y_test_random, test_preds_random)\n",
    "print(f\"\\n Final Test Accuracy (Random Epochs): {test_acc_random:.3f}\")\n",
    "print(classification_report(y_test_random, test_preds_random))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a1ba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_random, test_preds_random))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282ab55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_random = confusion_matrix(y_test_random, test_preds_random)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_random)\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "disp.plot(ax=ax, cmap = 'Blues', colorbar = True)\n",
    "plt.title(\"Confusion Matrix for Test Set Predictions - random epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e45bc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle \n",
    "\n",
    "# Load the label predictions CSV\n",
    "labels_df = pd.read_csv(\"label_predictions.csv\")\n",
    "\n",
    "# Dictionary to hold top 60 EO epochs per subject\n",
    "top_60_EO_epochs_per_subject = {}\n",
    "\n",
    "# Group by subject ID (assuming the column is 'subject_id')\n",
    "for subject_id, group in labels_df.groupby(\"Test subject ID\"):\n",
    "    # Filter epochs labeled as eyes-open (label == 0)\n",
    "    eyes_open_epochs = group[group[\"Label\"] == 0]\n",
    "\n",
    "    # Sort by probability descending to get highest confidence epochs first\n",
    "    eyes_open_sorted = eyes_open_epochs.sort_values(by=\"Probability\", ascending=False)\n",
    "\n",
    "    # Take top 60 epoch numbers (or fewer if less than 60 available)\n",
    "    top_epochs = eyes_open_sorted.head(60)[\"Epoch number\"].values\n",
    "\n",
    "    # Store in dictionary\n",
    "    top_60_EO_epochs_per_subject[subject_id] = top_epochs\n",
    "\n",
    "with open(\"top_60_EO_epochs_per_subject.pkl\", \"wb\") as f:\n",
    "    pickle.dump(top_60_EO_epochs_per_subject, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ccd3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# ------------ LOAD METADATA ------------\n",
    "metadata = pd.read_csv(\"metadata_time_filtered.csv\")\n",
    "metadata[\"subject_id\"] = metadata[\"subject_id\"].astype(str).str.strip()\n",
    "\n",
    "# Filter out subjects 90 or older\n",
    "metadata = metadata[metadata[\"age\"] < 90]\n",
    "\n",
    "# Use your previously created dictionary of top 60 EO epochs per subject\n",
    "# Make sure keys are strings and trimmed\n",
    "top_60_EO_epochs_per_subject = {str(k).strip(): v for k, v in top_60_EO_epochs_per_subject.items()}\n",
    "\n",
    "# Keep only subjects present in both metadata and EO dict\n",
    "all_subjects_EO = [s for s in top_60_EO_epochs_per_subject.keys() if s in metadata[\"subject_id\"].values]\n",
    "print(f\"Number of EO subjects: {len(all_subjects_EO)}\")\n",
    "\n",
    "# Use the SAME test_subjects list from random epochs code to ensure consistent hold-out set\n",
    "# (Make sure this list 'test_subjects' is already defined and contains subject IDs as strings)\n",
    "test_subjects_EO = test_subjects\n",
    "train_subjects_EO = [s for s in all_subjects_EO if s not in test_subjects_EO]\n",
    "\n",
    "# Define age groups (decades)\n",
    "def assign_age_group(age):\n",
    "    return age // 10\n",
    "\n",
    "metadata[\"age_group\"] = metadata[\"age\"].apply(assign_age_group)\n",
    "metadata = metadata[metadata[\"subject_id\"].isin(all_subjects_EO)]\n",
    "\n",
    "# ------------ FEATURE EXTRACTION ------------\n",
    "def extract_combined_features_EO(subject_id, epoch_indices, set_folder):\n",
    "    path = f\"{set_folder}/{subject_id}_epoched.set\"\n",
    "    epochs = mne.io.read_epochs_eeglab(path, verbose='ERROR')\n",
    "    data = epochs.get_data()[epoch_indices]\n",
    "    sfreq = epochs.info[\"sfreq\"]\n",
    "\n",
    "    bands = {\n",
    "        \"delta\": (1, 4),\n",
    "        \"theta\": (4, 8),\n",
    "        \"alpha\": (8, 13),\n",
    "        \"beta\": (13, 30),\n",
    "    }\n",
    "    \n",
    "    band_powers = []\n",
    "    relative_powers = []\n",
    "\n",
    "    # Total PSD for 1-45 Hz (for relative power & spectral slope)\n",
    "    total_psds, total_freqs = mne.time_frequency.psd_array_welch(\n",
    "        data, sfreq=sfreq, fmin=1, fmax=45, n_fft=128, verbose=False\n",
    "    )\n",
    "    total_power = total_psds.sum(axis=-1)  # shape: (epochs, channels)\n",
    "\n",
    "    # Spectral slope calculation\n",
    "    mean_psd = total_psds.mean(axis=(0,1))  # mean over epochs and channels\n",
    "    freqs_log = np.log10(total_freqs)\n",
    "    psd_log = np.log10(mean_psd)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(freqs_log.reshape(-1,1), psd_log)\n",
    "    spectral_slope = model.coef_[0]\n",
    "\n",
    "    # Alpha peak frequency\n",
    "    psds_alpha, freqs_alpha = mne.time_frequency.psd_array_welch(\n",
    "        data, sfreq=sfreq, fmin=8, fmax=13, n_fft=128, verbose=False\n",
    "    )\n",
    "    mean_alpha_psd = psds_alpha.mean(axis=(0,1))\n",
    "    alpha_peak_idx = mean_alpha_psd.argmax()\n",
    "    alpha_peak_freq = freqs_alpha[alpha_peak_idx]\n",
    "\n",
    "    # Band powers & relative powers\n",
    "    for band_name, (fmin, fmax) in bands.items():\n",
    "        psds_band, _ = mne.time_frequency.psd_array_welch(\n",
    "            data, sfreq=sfreq, fmin=fmin, fmax=fmax, n_fft=128, verbose=False\n",
    "        )\n",
    "        abs_power = psds_band.mean(axis=(0,2))\n",
    "        band_powers.extend(abs_power)\n",
    "        \n",
    "        rel_power = (psds_band.sum(axis=-1) / total_power).mean()\n",
    "        relative_powers.append(rel_power)\n",
    "    \n",
    "    features = np.concatenate([band_powers, relative_powers, [spectral_slope, alpha_peak_freq]])\n",
    "    return features\n",
    "\n",
    "# ------------ EXTRACT FEATURES FROM TRAIN SET ------------\n",
    "set_folder = \"G:/ChristianMusaeus/Preprocessed_setfiles\"  # <-- Update this path\n",
    "\n",
    "X_EO, y_EO, subject_ids_EO = [], [], []\n",
    "\n",
    "for subj_id in train_subjects_EO:\n",
    "    try:\n",
    "        epoch_inds = top_60_EO_epochs_per_subject[subj_id]\n",
    "        features = extract_combined_features_EO(subj_id, epoch_inds, set_folder)\n",
    "        age_group = metadata.loc[metadata[\"subject_id\"] == subj_id, \"age_group\"].values[0]\n",
    "        X_EO.append(features)\n",
    "        y_EO.append(age_group)\n",
    "        subject_ids_EO.append(subj_id)\n",
    "    except Exception as e:\n",
    "        print(f\" Error processing {subj_id}: {e}\")\n",
    "\n",
    "X_EO = np.array(X_EO)\n",
    "y_EO = np.array(y_EO)\n",
    "\n",
    "# ------------ 5-FOLD CROSS VALIDATION ------------\n",
    "skf_EO = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies_EO = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf_EO.split(X_EO, y_EO), start=1):\n",
    "    print(f\"\\n Fold {fold} running...\")\n",
    "    X_train, X_val = X_EO[train_idx], X_EO[val_idx]\n",
    "    y_train, y_val = y_EO[train_idx], y_EO[val_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    model_EO = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "    model_EO.fit(X_train_scaled, y_train)\n",
    "\n",
    "    preds_EO = model_EO.predict(X_val_scaled)\n",
    "    acc = accuracy_score(y_val, preds_EO)\n",
    "    accuracies_EO.append(acc)\n",
    "    print(f\"Fold {fold} Accuracy: {acc:.3f}\")\n",
    "\n",
    "print(f\"\\n Mean CV Accuracy (EO epochs): {np.mean(accuracies_EO):.3f}\")\n",
    "\n",
    "# ------------ FINAL MODEL TRAINING ------------\n",
    "scaler = StandardScaler()\n",
    "X_scaled_EO = scaler.fit_transform(X_EO)\n",
    "final_model_EO = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "final_model_EO.fit(X_scaled_EO, y_EO)\n",
    "\n",
    "# ------------ TEST SET EVALUATION ------------\n",
    "X_test_EO, y_test_EO = [], []\n",
    "\n",
    "for subj_id in test_subjects_EO:\n",
    "    try:\n",
    "        epoch_inds = top_60_EO_epochs_per_subject[subj_id]\n",
    "        features = extract_combined_features_EO(subj_id, epoch_inds, set_folder)\n",
    "        age_group = metadata.loc[metadata[\"subject_id\"] == subj_id, \"age_group\"].values[0]\n",
    "        X_test_EO.append(features)\n",
    "        y_test_EO.append(age_group)\n",
    "    except Exception as e:\n",
    "        print(f\" Error processing test subject {subj_id}: {e}\")\n",
    "\n",
    "X_test_EO = np.array(X_test_EO)\n",
    "y_test_EO = np.array(y_test_EO)\n",
    "X_test_scaled_EO = scaler.transform(X_test_EO)\n",
    "\n",
    "test_preds_EO = final_model_EO.predict(X_test_scaled_EO)\n",
    "test_acc_EO = accuracy_score(y_test_EO, test_preds_EO)\n",
    "print(f\"\\n Final Test Accuracy (EO epochs): {test_acc_EO:.3f}\")\n",
    "print(classification_report(y_test_EO, test_preds_EO))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea41602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_EO, test_preds_EO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6194a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_EO = confusion_matrix(y_test_EO, test_preds_EO)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_EO)\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "disp.plot(ax=ax, cmap = 'Blues', colorbar = True)\n",
    "plt.title(\"Confusion Matrix for Test Set Predictions - Eyes Open Epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cf24eb",
   "metadata": {},
   "source": [
    "# Plotting the mean absolute alpha power for those same 60 random epochs as chosen before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5437639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.time_frequency import psd_array_welch\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# ------------ Load metadata ------------\n",
    "metadata = pd.read_csv(\"metadata_time_filtered.csv\")\n",
    "metadata[\"subject_id\"] = metadata[\"subject_id\"].astype(str)\n",
    "\n",
    "# ------------ Compute mean alpha power for random epochs ------------\n",
    "alpha_by_subject_random = {}\n",
    "set_folder = \"G:/ChristianMusaeus/Preprocessed_setfiles\"  # Update this path\n",
    "\n",
    "for subject_id in random_epochs_per_subject:\n",
    "    try:\n",
    "        set_path = f\"{set_folder}/{subject_id}_epoched.set\"\n",
    "        epochs = mne.io.read_epochs_eeglab(set_path, verbose='ERROR')\n",
    "        data = epochs.get_data()[random_epochs_per_subject[subject_id]]\n",
    "\n",
    "        psds, freqs = psd_array_welch(\n",
    "            data,\n",
    "            sfreq=epochs.info[\"sfreq\"],\n",
    "            fmin=8, fmax=13,\n",
    "            n_fft=200,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        mean_power_per_channel = psds.mean(axis=-1)\n",
    "        mean_power_over_epochs = mean_power_per_channel.mean(axis=0)\n",
    "        alpha_value = mean_power_over_epochs.mean() * 1e12  # µV²/Hz\n",
    "\n",
    "        alpha_by_subject_random[subject_id] = alpha_value\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Could not process {subject_id}: {e}\")\n",
    "\n",
    "# ------------ Merge alpha values with metadata ------------\n",
    "alpha_df = pd.DataFrame({\n",
    "    \"subject_id\": list(alpha_by_subject_random.keys()),\n",
    "    \"alpha_power\": list(alpha_by_subject_random.values())\n",
    "})\n",
    "\n",
    "metadata_subset = metadata[metadata[\"subject_id\"].isin(alpha_df[\"subject_id\"])]\n",
    "\n",
    "alpha_df[\"subject_id\"] = alpha_df[\"subject_id\"].astype(str)\n",
    "metadata_subset[\"subject_id\"] = metadata_subset[\"subject_id\"].astype(str)\n",
    "\n",
    "merged = pd.merge(alpha_df, metadata_subset, on=\"subject_id\")\n",
    "\n",
    "# Filter out extreme alpha power values\n",
    "merged = merged[merged[\"alpha_power\"] <= 20]\n",
    "\n",
    "# ------------ Group by age ------------\n",
    "grouped = merged.groupby(\"age\").agg(\n",
    "    mean_alpha=(\"alpha_power\", \"mean\"),\n",
    "    std=(\"alpha_power\", \"std\"),\n",
    "    N=(\"alpha_power\", \"count\")\n",
    ").reset_index()\n",
    "\n",
    "grouped[\"sem\"] = grouped[\"std\"] / np.sqrt(grouped[\"N\"])\n",
    "grouped[\"ci_upper\"] = grouped[\"mean_alpha\"] + 1.96 * grouped[\"sem\"]\n",
    "grouped[\"ci_lower\"] = grouped[\"mean_alpha\"] - 1.96 * grouped[\"sem\"]\n",
    "\n",
    "# Remove NaNs/Infs for smoothing\n",
    "valid_idx = (~grouped[\"ci_upper\"].isna()) & (~grouped[\"ci_lower\"].isna()) & \\\n",
    "            (~grouped[\"ci_upper\"].isin([np.inf, -np.inf])) & (~grouped[\"ci_lower\"].isin([np.inf, -np.inf]))\n",
    "\n",
    "ages = grouped.loc[valid_idx, \"age\"].values\n",
    "mean_alpha = grouped.loc[valid_idx, \"mean_alpha\"].values\n",
    "ci_upper = grouped.loc[valid_idx, \"ci_upper\"].values\n",
    "ci_lower = grouped.loc[valid_idx, \"ci_lower\"].values\n",
    "\n",
    "# Create smooth x values\n",
    "ages_smooth = np.linspace(ages.min(), ages.max(), 500)\n",
    "\n",
    "# Fit splines (degree k=5)\n",
    "mean_spline = make_interp_spline(ages, mean_alpha, k=5)\n",
    "ci_upper_spline = make_interp_spline(ages, ci_upper, k=5)\n",
    "ci_lower_spline = make_interp_spline(ages, ci_lower, k=5)\n",
    "\n",
    "# Evaluate splines\n",
    "mean_smooth = mean_spline(ages_smooth)\n",
    "ci_upper_smooth = ci_upper_spline(ages_smooth)\n",
    "ci_lower_smooth = ci_lower_spline(ages_smooth)\n",
    "\n",
    "# ------------ Plot ------------\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(ages_smooth, mean_smooth, label=\"Smoothed Mean\", color=\"blue\")\n",
    "plt.fill_between(ages_smooth, ci_lower_smooth, ci_upper_smooth, color=\"skyblue\", alpha=0.4, label=\"95% CI\")\n",
    "plt.scatter(ages, mean_alpha, color=\"blue\", s=10, label=\"Mean Alpha Power\")\n",
    "\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Mean Alpha Power (µV²/Hz)\")\n",
    "plt.title(\"Mean Absolute Alpha Power vs. Age (Random Epochs) with 95% Confidence Interval\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9069c463",
   "metadata": {},
   "source": [
    "# Plotting the mean relative alpha power for those same 60 random epochs as chosen before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6e6d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.time_frequency import psd_array_welch\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# ------------ Load metadata ------------\n",
    "metadata = pd.read_csv(\"metadata_time_filtered.csv\")\n",
    "metadata[\"subject_id\"] = metadata[\"subject_id\"].astype(str)\n",
    "\n",
    "# ------------ Compute mean relative alpha power for random epochs ------------\n",
    "relative_alpha_by_subject = {}\n",
    "set_folder = \"G:/ChristianMusaeus/Preprocessed_setfiles\"  # Update this path\n",
    "\n",
    "for subject_id in random_epochs_per_subject:\n",
    "    try:\n",
    "        set_path = f\"{set_folder}/{subject_id}_epoched.set\"\n",
    "        epochs = mne.io.read_epochs_eeglab(set_path, verbose='ERROR')\n",
    "        selected_data = epochs.get_data()[random_epochs_per_subject[subject_id]]\n",
    "\n",
    "        # Alpha power (8–13 Hz)\n",
    "        psds_alpha, _ = psd_array_welch(\n",
    "            selected_data,\n",
    "            sfreq=epochs.info[\"sfreq\"],\n",
    "            fmin=8, fmax=13,\n",
    "            n_fft=200,\n",
    "            verbose=False\n",
    "        )\n",
    "        alpha_power = psds_alpha.sum(axis=-1).mean()  # sum over freq bins, mean over epochs & channels\n",
    "\n",
    "        # Total power (1–40 Hz)\n",
    "        psds_total, _ = psd_array_welch(\n",
    "            selected_data,\n",
    "            sfreq=epochs.info[\"sfreq\"],\n",
    "            fmin=1, fmax=40,\n",
    "            n_fft=200,\n",
    "            verbose=False\n",
    "        )\n",
    "        total_power = psds_total.sum(axis=-1).mean()\n",
    "\n",
    "        # Relative alpha power\n",
    "        relative_alpha = alpha_power / total_power\n",
    "        relative_alpha_by_subject[subject_id] = relative_alpha\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Could not process {subject_id}: {e}\")\n",
    "\n",
    "# ------------ Merge relative alpha values with metadata ------------\n",
    "alpha_df = pd.DataFrame({\n",
    "    \"subject_id\": list(relative_alpha_by_subject.keys()),\n",
    "    \"relative_alpha_power\": list(relative_alpha_by_subject.values())\n",
    "})\n",
    "\n",
    "metadata_subset = metadata[metadata[\"subject_id\"].isin(alpha_df[\"subject_id\"])]\n",
    "\n",
    "alpha_df[\"subject_id\"] = alpha_df[\"subject_id\"].astype(str)\n",
    "metadata_subset[\"subject_id\"] = metadata_subset[\"subject_id\"].astype(str)\n",
    "\n",
    "merged = pd.merge(alpha_df, metadata_subset, on=\"subject_id\")\n",
    "\n",
    "# Filter out extreme relative alpha values (optional, adjust threshold as needed)\n",
    "merged = merged[merged[\"relative_alpha_power\"] <= 1.0]\n",
    "\n",
    "# ------------ Group by age ------------\n",
    "grouped = merged.groupby(\"age\").agg(\n",
    "    mean_rel_alpha=(\"relative_alpha_power\", \"mean\"),\n",
    "    std=(\"relative_alpha_power\", \"std\"),\n",
    "    N=(\"relative_alpha_power\", \"count\")\n",
    ").reset_index()\n",
    "\n",
    "grouped[\"sem\"] = grouped[\"std\"] / np.sqrt(grouped[\"N\"])\n",
    "grouped[\"ci_upper\"] = grouped[\"mean_rel_alpha\"] + 1.96 * grouped[\"sem\"]\n",
    "grouped[\"ci_lower\"] = grouped[\"mean_rel_alpha\"] - 1.96 * grouped[\"sem\"]\n",
    "\n",
    "# Remove NaNs/Infs for smoothing\n",
    "valid_idx = (~grouped[\"ci_upper\"].isna()) & (~grouped[\"ci_lower\"].isna()) & \\\n",
    "            (~grouped[\"ci_upper\"].isin([np.inf, -np.inf])) & (~grouped[\"ci_lower\"].isin([np.inf, -np.inf]))\n",
    "\n",
    "ages = grouped.loc[valid_idx, \"age\"].values\n",
    "mean_rel_alpha = grouped.loc[valid_idx, \"mean_rel_alpha\"].values\n",
    "ci_upper = grouped.loc[valid_idx, \"ci_upper\"].values\n",
    "ci_lower = grouped.loc[valid_idx, \"ci_lower\"].values\n",
    "\n",
    "# Create smooth x values\n",
    "ages_smooth = np.linspace(ages.min(), ages.max(), 500)\n",
    "\n",
    "# Fit splines (degree k=5)\n",
    "mean_spline = make_interp_spline(ages, mean_rel_alpha, k=5)\n",
    "ci_upper_spline = make_interp_spline(ages, ci_upper, k=5)\n",
    "ci_lower_spline = make_interp_spline(ages, ci_lower, k=5)\n",
    "\n",
    "# Evaluate splines\n",
    "mean_smooth = mean_spline(ages_smooth)\n",
    "ci_upper_smooth = ci_upper_spline(ages_smooth)\n",
    "ci_lower_smooth = ci_lower_spline(ages_smooth)\n",
    "\n",
    "# ------------ Plot ------------\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(ages_smooth, mean_smooth, label=\"Smoothed Mean Relative Alpha\", color=\"blue\")\n",
    "plt.fill_between(ages_smooth, ci_lower_smooth, ci_upper_smooth, color=\"skyblue\", alpha=0.4, label=\"95% CI\")\n",
    "plt.scatter(ages, mean_rel_alpha, color=\"blue\", s=10, label=\"Mean Relative Alpha\")\n",
    "\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Mean Relative Alpha Power\")\n",
    "plt.title(\"Mean Relative Alpha Power vs. Age (Random Epochs) with 95% Confidence Interval\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c261a0b",
   "metadata": {},
   "source": [
    "# Plotting absolute mean alpha for 60 eyes open epochs per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740026b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.time_frequency import psd_array_welch\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# ------------ Load metadata ------------\n",
    "metadata = pd.read_csv(\"metadata_time_filtered.csv\")\n",
    "metadata[\"subject_id\"] = metadata[\"subject_id\"].astype(str)\n",
    "\n",
    "# ------------ Compute mean alpha power for random epochs ------------\n",
    "alpha_by_subject_random = {}\n",
    "set_folder = \"G:/ChristianMusaeus/Preprocessed_setfiles\"  # Update this path\n",
    "\n",
    "for subject_id in top_60_EO_epochs_per_subject:\n",
    "    try:\n",
    "        set_path = f\"{set_folder}/{subject_id}_epoched.set\"\n",
    "        epochs = mne.io.read_epochs_eeglab(set_path, verbose='ERROR')\n",
    "        data = epochs.get_data()[top_60_EO_epochs_per_subject[subject_id]]\n",
    "\n",
    "        psds, freqs = psd_array_welch(\n",
    "            data,\n",
    "            sfreq=epochs.info[\"sfreq\"],\n",
    "            fmin=8, fmax=13,\n",
    "            n_fft=200,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        mean_power_per_channel = psds.mean(axis=-1)\n",
    "        mean_power_over_epochs = mean_power_per_channel.mean(axis=0)\n",
    "        alpha_value = mean_power_over_epochs.mean() * 1e12  # µV²/Hz\n",
    "\n",
    "        alpha_by_subject_random[subject_id] = alpha_value\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Could not process {subject_id}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca2a17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ Merge alpha values with metadata ------------\n",
    "alpha_df = pd.DataFrame({\n",
    "    \"subject_id\": list(alpha_by_subject_random.keys()),\n",
    "    \"alpha_power\": list(alpha_by_subject_random.values())\n",
    "})\n",
    "\n",
    "metadata_subset = metadata[metadata[\"subject_id\"].isin(alpha_df[\"subject_id\"])]\n",
    "\n",
    "alpha_df[\"subject_id\"] = alpha_df[\"subject_id\"].astype(str)\n",
    "metadata_subset[\"subject_id\"] = metadata_subset[\"subject_id\"].astype(str)\n",
    "\n",
    "merged = pd.merge(alpha_df, metadata_subset, on=\"subject_id\")\n",
    "\n",
    "# Filter out extreme alpha power values\n",
    "merged = merged[merged[\"alpha_power\"] <= 20]\n",
    "\n",
    "# ------------ Group by age ------------\n",
    "grouped = merged.groupby(\"age\").agg(\n",
    "    mean_alpha=(\"alpha_power\", \"mean\"),\n",
    "    std=(\"alpha_power\", \"std\"),\n",
    "    N=(\"alpha_power\", \"count\")\n",
    ").reset_index()\n",
    "\n",
    "grouped[\"sem\"] = grouped[\"std\"] / np.sqrt(grouped[\"N\"])\n",
    "grouped[\"ci_upper\"] = grouped[\"mean_alpha\"] + 1.96 * grouped[\"sem\"]\n",
    "grouped[\"ci_lower\"] = grouped[\"mean_alpha\"] - 1.96 * grouped[\"sem\"]\n",
    "\n",
    "# Remove NaNs/Infs for smoothing\n",
    "valid_idx = (~grouped[\"ci_upper\"].isna()) & (~grouped[\"ci_lower\"].isna()) & \\\n",
    "            (~grouped[\"ci_upper\"].isin([np.inf, -np.inf])) & (~grouped[\"ci_lower\"].isin([np.inf, -np.inf]))\n",
    "\n",
    "ages = grouped.loc[valid_idx, \"age\"].values\n",
    "mean_alpha = grouped.loc[valid_idx, \"mean_alpha\"].values\n",
    "ci_upper = grouped.loc[valid_idx, \"ci_upper\"].values\n",
    "ci_lower = grouped.loc[valid_idx, \"ci_lower\"].values\n",
    "\n",
    "# Create smooth x values\n",
    "ages_smooth = np.linspace(ages.min(), ages.max(), 500)\n",
    "\n",
    "# Fit splines (degree k=5)\n",
    "mean_spline = make_interp_spline(ages, mean_alpha, k=5)\n",
    "ci_upper_spline = make_interp_spline(ages, ci_upper, k=5)\n",
    "ci_lower_spline = make_interp_spline(ages, ci_lower, k=5)\n",
    "\n",
    "# Evaluate splines\n",
    "mean_smooth = mean_spline(ages_smooth)\n",
    "ci_upper_smooth = ci_upper_spline(ages_smooth)\n",
    "ci_lower_smooth = ci_lower_spline(ages_smooth)\n",
    "\n",
    "# ------------ Plot ------------\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(ages_smooth, mean_smooth, label=\"Smoothed Mean\", color=\"blue\")\n",
    "plt.fill_between(ages_smooth, ci_lower_smooth, ci_upper_smooth, color=\"skyblue\", alpha=0.4, label=\"95% CI\")\n",
    "plt.scatter(ages, mean_alpha, color=\"blue\", s=10, label=\"Mean Alpha Power\")\n",
    "\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Mean Alpha Power (µV²/Hz)\")\n",
    "plt.title(\"Mean Absolute Alpha Power vs. Age (EO Epochs) with 95% Confidence Interval\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(np.arange(0,100,10))\n",
    "plt.yticks(np.arange(-2,9,1))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ae8a49",
   "metadata": {},
   "source": [
    "# Plotting relative mean alpha for 60 eyes open epochs per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad381c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.time_frequency import psd_array_welch\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# ------------ Load metadata ------------\n",
    "metadata = pd.read_csv(\"metadata_time_filtered.csv\")\n",
    "metadata[\"subject_id\"] = metadata[\"subject_id\"].astype(str)\n",
    "\n",
    "# ------------ Compute mean relative alpha power for random epochs ------------\n",
    "relative_alpha_by_subject = {}\n",
    "set_folder = \"G:/ChristianMusaeus/Preprocessed_setfiles\"  # Update this path\n",
    "\n",
    "for subject_id in top_60_EO_epochs_per_subject:\n",
    "    try:\n",
    "        set_path = f\"{set_folder}/{subject_id}_epoched.set\"\n",
    "        epochs = mne.io.read_epochs_eeglab(set_path, verbose='ERROR')\n",
    "        selected_data = epochs.get_data()[top_60_EO_epochs_per_subject[subject_id]]\n",
    "\n",
    "        # Alpha power (8–13 Hz)\n",
    "        psds_alpha, _ = psd_array_welch(\n",
    "            selected_data,\n",
    "            sfreq=epochs.info[\"sfreq\"],\n",
    "            fmin=8, fmax=13,\n",
    "            n_fft=200,\n",
    "            verbose=False\n",
    "        )\n",
    "        alpha_power = psds_alpha.sum(axis=-1).mean()  # sum over freq bins, mean over epochs & channels\n",
    "\n",
    "        # Total power (1–40 Hz)\n",
    "        psds_total, _ = psd_array_welch(\n",
    "            selected_data,\n",
    "            sfreq=epochs.info[\"sfreq\"],\n",
    "            fmin=1, fmax=40,\n",
    "            n_fft=200,\n",
    "            verbose=False\n",
    "        )\n",
    "        total_power = psds_total.sum(axis=-1).mean()\n",
    "\n",
    "        # Relative alpha power\n",
    "        relative_alpha = alpha_power / total_power\n",
    "        relative_alpha_by_subject[subject_id] = relative_alpha\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Could not process {subject_id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c772bd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ Merge relative alpha values with metadata ------------\n",
    "alpha_df = pd.DataFrame({\n",
    "    \"subject_id\": list(relative_alpha_by_subject.keys()),\n",
    "    \"relative_alpha_power\": list(relative_alpha_by_subject.values())\n",
    "})\n",
    "\n",
    "metadata_subset = metadata[metadata[\"subject_id\"].isin(alpha_df[\"subject_id\"])]\n",
    "\n",
    "alpha_df[\"subject_id\"] = alpha_df[\"subject_id\"].astype(str)\n",
    "metadata_subset[\"subject_id\"] = metadata_subset[\"subject_id\"].astype(str)\n",
    "\n",
    "merged = pd.merge(alpha_df, metadata_subset, on=\"subject_id\")\n",
    "\n",
    "# Filter out extreme relative alpha values (optional, adjust threshold as needed)\n",
    "merged = merged[merged[\"relative_alpha_power\"] <= 1.0]\n",
    "\n",
    "# ------------ Group by age ------------\n",
    "grouped = merged.groupby(\"age\").agg(\n",
    "    mean_rel_alpha=(\"relative_alpha_power\", \"mean\"),\n",
    "    std=(\"relative_alpha_power\", \"std\"),\n",
    "    N=(\"relative_alpha_power\", \"count\")\n",
    ").reset_index()\n",
    "\n",
    "grouped[\"sem\"] = grouped[\"std\"] / np.sqrt(grouped[\"N\"])\n",
    "grouped[\"ci_upper\"] = grouped[\"mean_rel_alpha\"] + 1.96 * grouped[\"sem\"]\n",
    "grouped[\"ci_lower\"] = grouped[\"mean_rel_alpha\"] - 1.96 * grouped[\"sem\"]\n",
    "\n",
    "# Remove NaNs/Infs for smoothing\n",
    "valid_idx = (~grouped[\"ci_upper\"].isna()) & (~grouped[\"ci_lower\"].isna()) & \\\n",
    "            (~grouped[\"ci_upper\"].isin([np.inf, -np.inf])) & (~grouped[\"ci_lower\"].isin([np.inf, -np.inf]))\n",
    "\n",
    "ages = grouped.loc[valid_idx, \"age\"].values\n",
    "mean_rel_alpha = grouped.loc[valid_idx, \"mean_rel_alpha\"].values\n",
    "ci_upper = grouped.loc[valid_idx, \"ci_upper\"].values\n",
    "ci_lower = grouped.loc[valid_idx, \"ci_lower\"].values\n",
    "\n",
    "# Create smooth x values\n",
    "ages_smooth = np.linspace(ages.min(), ages.max(), 500)\n",
    "\n",
    "# Fit splines (degree k=5)\n",
    "mean_spline = make_interp_spline(ages, mean_rel_alpha, k=5)\n",
    "ci_upper_spline = make_interp_spline(ages, ci_upper, k=5)\n",
    "ci_lower_spline = make_interp_spline(ages, ci_lower, k=5)\n",
    "\n",
    "# Evaluate splines\n",
    "mean_smooth = mean_spline(ages_smooth)\n",
    "ci_upper_smooth = ci_upper_spline(ages_smooth)\n",
    "ci_lower_smooth = ci_lower_spline(ages_smooth)\n",
    "\n",
    "# ------------ Plot ------------\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(ages_smooth, mean_smooth, label=\"Smoothed Mean Relative Alpha\", color=\"blue\")\n",
    "plt.fill_between(ages_smooth, ci_lower_smooth, ci_upper_smooth, color=\"skyblue\", alpha=0.4, label=\"95% CI\")\n",
    "plt.scatter(ages, mean_rel_alpha, color=\"blue\", s=10, label=\"Mean Relative Alpha\")\n",
    "\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Mean Relative Alpha Power\")\n",
    "plt.title(\"Mean Relative Alpha Power vs. Age (EO Epochs) with 95% Confidence Interval\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5371977",
   "metadata": {},
   "source": [
    "# Plotting absolute mean alpha power in the occipital channels for eyes open epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c3585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne.time_frequency import psd_array_welch\n",
    "import numpy as np\n",
    "\n",
    "alpha_by_subject_occipital = {}\n",
    "\n",
    "for subject_id in list(top_60_EO_epochs_per_subject.keys()):\n",
    "    print(f\"Processing alpha for {subject_id}...\")\n",
    "\n",
    "    set_path = f\"G:/ChristianMusaeus/Preprocessed_setfiles/{subject_id}_epoched.set\"\n",
    "\n",
    "    try:\n",
    "        epochs = mne.io.read_epochs_eeglab(set_path, verbose='ERROR')\n",
    "        selected_data = epochs.get_data()[top_60_EO_epochs_per_subject[subject_id]]  # (60, channels, timepoints)\n",
    "\n",
    "        psds, freqs = psd_array_welch(\n",
    "            selected_data,\n",
    "            sfreq=epochs.info[\"sfreq\"],\n",
    "            fmin=8, fmax=13,\n",
    "            n_fft=128,\n",
    "            verbose=False\n",
    "        )\n",
    "        mean_power_per_channel = psds.mean(axis=-1)\n",
    "        mean_power_over_epochs = mean_power_per_channel.mean(axis = 0)\n",
    "        alpha_value = mean_power_over_epochs[8:10].mean() * 1e12\n",
    "\n",
    "        alpha_by_subject_occipital[subject_id] = alpha_value\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Could not process {subject_id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3704a9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ Load metadata and merge ------------\n",
    "\n",
    "metadata = pd.read_csv(\"metadata_time_filtered.csv\")\n",
    "metadata[\"subject_id\"] = metadata[\"subject_id\"].astype(str)\n",
    "\n",
    "alpha_df = pd.DataFrame({\n",
    "    \"subject_id\": list(alpha_by_subject_occipital.keys()),\n",
    "    \"alpha_power_occipital\": list(alpha_by_subject_occipital.values())\n",
    "})\n",
    "\n",
    "metadata_subset = metadata[metadata[\"subject_id\"].isin(alpha_df[\"subject_id\"])]\n",
    "\n",
    "alpha_df[\"subject_id\"] = alpha_df[\"subject_id\"].astype(str)\n",
    "metadata_subset[\"subject_id\"] = metadata_subset[\"subject_id\"].astype(str)\n",
    "\n",
    "merged = pd.merge(alpha_df, metadata_subset, on=\"subject_id\")\n",
    "\n",
    "# Filter out extreme values if needed\n",
    "merged = merged[merged[\"alpha_power_occipital\"] <= 20]\n",
    "\n",
    "# ------------ Group by age ------------\n",
    "\n",
    "grouped = merged.groupby(\"age\").agg(\n",
    "    MeanAlpha=(\"alpha_power_occipital\", \"mean\"),\n",
    "    Std=(\"alpha_power_occipital\", \"std\"),\n",
    "    Count=(\"alpha_power_occipital\", \"count\")\n",
    ").reset_index()\n",
    "\n",
    "grouped[\"SEM\"] = grouped[\"Std\"] / np.sqrt(grouped[\"Count\"])\n",
    "grouped[\"Upper\"] = grouped[\"MeanAlpha\"] + 1.96 * grouped[\"SEM\"]\n",
    "grouped[\"Lower\"] = grouped[\"MeanAlpha\"] - 1.96 * grouped[\"SEM\"]\n",
    "\n",
    "# Remove NaNs and inf values for smoothing\n",
    "grouped_clean = grouped.replace([np.inf, -np.inf], np.nan).dropna(subset=[\"age\", \"MeanAlpha\", \"Lower\", \"Upper\"])\n",
    "\n",
    "# ------------ Prepare for smoothing ------------\n",
    "\n",
    "x = grouped_clean[\"age\"].values\n",
    "y = grouped_clean[\"MeanAlpha\"].values\n",
    "y_lower = grouped_clean[\"Lower\"].values\n",
    "y_upper = grouped_clean[\"Upper\"].values\n",
    "\n",
    "x_smooth = np.linspace(x.min(), x.max(), 1000)\n",
    "\n",
    "spline_mean = make_interp_spline(x, y, k=5)\n",
    "spline_lower = make_interp_spline(x, y_lower, k=5)\n",
    "spline_upper = make_interp_spline(x, y_upper, k=5)\n",
    "\n",
    "y_smooth = spline_mean(x_smooth)\n",
    "y_lower_smooth = spline_lower(x_smooth)\n",
    "y_upper_smooth = spline_upper(x_smooth)\n",
    "\n",
    "# ------------ Plot ------------\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(x, y, color='blue', s=30, label=\"Mean Alpha Power (Occipital)\")\n",
    "plt.plot(x_smooth, y_smooth, color='blue', label=\"Smoothed Mean\")\n",
    "plt.fill_between(x_smooth, y_lower_smooth, y_upper_smooth, color='skyblue', alpha=0.4, label=\"95% CI\")\n",
    "\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Mean Absolute Alpha Power (µV²/Hz)\")\n",
    "plt.title(\"Mean Absolute Alpha Power vs. Age (Occipital Channels) with 95% Confidence Interval\")\n",
    "plt.grid(True)\n",
    "plt.xticks(np.arange(0, 100, 10))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4043262",
   "metadata": {},
   "source": [
    "# Regression model eyes closed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9b0d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# ------------ LOAD DATA ------------\n",
    "with open(\"top_epochs_per_subject.pkl\", \"rb\") as f:\n",
    "    top_epochs_per_subject = pickle.load(f)\n",
    "\n",
    "top_epochs_per_subject = {str(k).strip(): v for k, v in top_epochs_per_subject.items()}\n",
    "\n",
    "metadata = pd.read_csv(\"metadata_time_filtered.csv\")\n",
    "metadata[\"subject_id\"] = metadata[\"subject_id\"].astype(str).str.strip()\n",
    "\n",
    "metadata = metadata[metadata[\"age\"] < 90]\n",
    "\n",
    "all_subjects = [s for s in top_epochs_per_subject.keys() if s in metadata[\"subject_id\"].values]\n",
    "\n",
    "random.seed(42)\n",
    "test_subjects = random.sample(all_subjects, 500)\n",
    "train_subjects = [s for s in all_subjects if s not in test_subjects]\n",
    "\n",
    "# ------------ FEATURE EXTRACTION ------------\n",
    "def extract_combined_features(subject_id, epoch_indices, set_folder):\n",
    "    path = f\"{set_folder}/{subject_id}_epoched.set\"\n",
    "    epochs = mne.io.read_epochs_eeglab(path, verbose='ERROR')\n",
    "    data = epochs.get_data()[epoch_indices]\n",
    "    sfreq = epochs.info[\"sfreq\"]\n",
    "\n",
    "    bands = {\n",
    "        \"delta\": (1, 4),\n",
    "        \"theta\": (4, 8),\n",
    "        \"alpha\": (8, 13),\n",
    "        \"beta\": (13, 30),\n",
    "    }\n",
    "    \n",
    "    band_powers = []\n",
    "    relative_powers = []\n",
    "\n",
    "    total_psds, total_freqs = mne.time_frequency.psd_array_welch(\n",
    "        data, sfreq=sfreq, fmin=1, fmax=45, n_fft=128, verbose=False\n",
    "    )\n",
    "    total_power = total_psds.sum(axis=-1)\n",
    "\n",
    "    mean_psd = total_psds.mean(axis=(0,1))\n",
    "    freqs_log = np.log10(total_freqs)\n",
    "    psd_log = np.log10(mean_psd)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(freqs_log.reshape(-1,1), psd_log)\n",
    "    spectral_slope = model.coef_[0]\n",
    "\n",
    "    psds_alpha, freqs_alpha = mne.time_frequency.psd_array_welch(\n",
    "        data, sfreq=sfreq, fmin=8, fmax=13, n_fft=128, verbose=False\n",
    "    )\n",
    "    mean_alpha_psd = psds_alpha.mean(axis=(0,1))\n",
    "    alpha_peak_idx = mean_alpha_psd.argmax()\n",
    "    alpha_peak_freq = freqs_alpha[alpha_peak_idx]\n",
    "\n",
    "    for band_name, (fmin, fmax) in bands.items():\n",
    "        psds_band, _ = mne.time_frequency.psd_array_welch(\n",
    "            data, sfreq=sfreq, fmin=fmin, fmax=fmax, n_fft=128, verbose=False\n",
    "        )\n",
    "        abs_power = psds_band.mean(axis=(0,2))\n",
    "        band_powers.extend(abs_power)\n",
    "        \n",
    "        rel_power = (psds_band.sum(axis=-1) / total_power).mean()\n",
    "        relative_powers.append(rel_power)\n",
    "    \n",
    "    features = np.concatenate([band_powers, relative_powers, [spectral_slope, alpha_peak_freq]])\n",
    "    return features\n",
    "\n",
    "# ------------ PREPARE TRAINING DATA ------------\n",
    "set_folder = \"G:/ChristianMusaeus/Preprocessed_setfiles\"\n",
    "\n",
    "X_train, y_train = [], []\n",
    "X_test, y_test = [], []\n",
    "\n",
    "for subj_id in train_subjects:\n",
    "    try:\n",
    "        epoch_inds = top_epochs_per_subject[subj_id]\n",
    "        features = extract_combined_features(subj_id, epoch_inds, set_folder)\n",
    "        age = metadata.loc[metadata[\"subject_id\"] == subj_id, \"age\"].values[0]\n",
    "        X_train.append(features)\n",
    "        y_train.append(age)\n",
    "    except Exception as e:\n",
    "        print(f\" Error processing train subject {subj_id}: {e}\")\n",
    "\n",
    "for subj_id in test_subjects:\n",
    "    try:\n",
    "        epoch_inds = top_epochs_per_subject[subj_id]\n",
    "        features = extract_combined_features(subj_id, epoch_inds, set_folder)\n",
    "        age = metadata.loc[metadata[\"subject_id\"] == subj_id, \"age\"].values[0]\n",
    "        X_test.append(features)\n",
    "        y_test.append(age)\n",
    "    except Exception as e:\n",
    "        print(f\" Error processing test subject {subj_id}: {e}\")\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "preds = model.predict(X_test_scaled)\n",
    "\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "r2 = r2_score(y_test, preds)\n",
    "\n",
    "print(f\"\\n Test Mean Absolute Error: {mae:.3f}\")\n",
    "print(f\" Test R^2 Score: {r2:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
