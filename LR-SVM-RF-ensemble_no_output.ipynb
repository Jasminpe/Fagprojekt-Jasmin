{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db4ba41d",
   "metadata": {},
   "source": [
    "# Nye modeller med hold out valideringss√¶t af 5 subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d5157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from scipy.io import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, classification_report, log_loss, roc_curve, auc\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57061cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eyes_open_files = [r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10002_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10135_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10136_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10138_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10139_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10140_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10142_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10148_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10155_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10158_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10160_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10161_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10165_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10166_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10169_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10171_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10174_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10175_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10188_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10189_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10190_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10192_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10193_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10194_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10195_p01_epoched_EyesOpen_marked.set',\n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10203_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10204_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10207_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10209_p01_epoched_EyesOpen_marked.set', \n",
    "                   r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10213_p01_epoched_EyesOpen_marked.set']\n",
    "eyes_closed_files = [r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10213_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10209_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10207_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10204_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10203_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10195_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10194_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10193_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10192_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10190_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10189_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10188_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10175_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10174_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10171_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10169_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10166_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10165_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10161_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10160_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10158_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10155_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10148_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10142_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10140_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10139_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10138_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10136_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10135_p01_epoched_60EpochsMarked.set',\n",
    "                      r'E:\\ChristianMusaeus\\Data\\Eyes_closed_marked\\10002_p01_epoched_60EpochsMarked.set']\n",
    "\n",
    "set_files = eyes_open_files+eyes_closed_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e872f4c2",
   "metadata": {},
   "source": [
    "### Pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f125d883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists to hold the data and labels\n",
    "X_list = []  # Features (PSD data)\n",
    "y_list = []  # Labels (eyes-open/eyes-closed)    \n",
    "subject_ids = []\n",
    "\n",
    "\n",
    "# loop through each subject\n",
    "for file in set_files:\n",
    "    # Load the .set file for the subject\n",
    "    epochs = mne.io.read_epochs_eeglab(file)\n",
    "    \n",
    "    # loading .set data as MATLAB to extract labels\n",
    "    mat = loadmat(file, struct_as_record=False, squeeze_me=True)\n",
    "    rejmanual = mat['reject'].rejmanual  # array of 0 and 1\n",
    "\n",
    "    # getting labels from rejmanual \n",
    "    labels = np.array(rejmanual, dtype=int)\n",
    "\n",
    "    # computing PSD for the current subject\n",
    "    psd = epochs.compute_psd()\n",
    "\n",
    "    # getting the PSD data and reshaping it (flattening the 3d array to 2d for logistic regression)\n",
    "    psd_data = psd.get_data()  # Shape: (n_epochs, n_channels, n_freqs)\n",
    "\n",
    "    # extracting marked epochs \n",
    "    eyes_marked = labels == 0\n",
    "    psd_data_marked = psd_data[eyes_marked]\n",
    "\n",
    "    # assigning labels based on file type\n",
    "    if file in eyes_closed_files:\n",
    "        final_labels = np.ones(psd_data_marked.shape[0], dtype=int)\n",
    "    else:\n",
    "        final_labels = np.zeros(psd_data_marked.shape[0], dtype=int)\n",
    "\n",
    "    # flattening the data into a 2d matrix \n",
    "    psd_data_final = psd_data_marked.reshape(psd_data_marked.shape[0], -1)  # Shape: (n_epochs, n_channels * n_freqs)\n",
    "\n",
    "    X_list.append(psd_data_final)\n",
    "    y_list.append(final_labels)\n",
    "\n",
    "    # Extracting the subject IDs from the file path\n",
    "    match = re.search(r'\\\\(\\d{5})_', file)\n",
    "    if match:\n",
    "        subject_id = int(match.group(1))\n",
    "    else:\n",
    "        raise ValueError(f\"Could not extract subject ID from path: {file}\")\n",
    "\n",
    "    subject_ids.extend([subject_id] * psd_data_final.shape[0])\n",
    "\n",
    "\n",
    "X_combined = np.vstack(X_list)  # Shape: (total_epochs, n_channels * n_freqs)\n",
    "y_combined = np.hstack(y_list)  # Shape: (total_epochs,)\n",
    "subject_ids = np.array(subject_ids)\n",
    "\n",
    "print(subject_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8c2e36",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a1a738",
   "metadata": {},
   "source": [
    "### The inner loop finds the optimal value for frequency bin number and regularization parameter C and trains the model on 25 of the 30 subjects, before testing the outer loop on the 5 subjects in the hold out test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f941686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 19\n",
    "n_freqs = X_combined.shape[1] // n_channels\n",
    "\n",
    "freq_bin_options = [5,10,15,20,25,30]\n",
    "C_grid = [0.01, 0.1,0.2,0.5,1]\n",
    "\n",
    "def reduce_freq_resolution(X, n_bins):\n",
    "    bin_size = n_freqs // n_bins\n",
    "    X_reshaped = X.reshape(-1, n_channels, n_freqs)\n",
    "    reduced = np.stack([\n",
    "        X_reshaped[:, :, i * bin_size:(i + 1) * bin_size].mean(axis=2)\n",
    "        for i in range(n_bins)\n",
    "    ], axis=2)\n",
    "    return reduced.reshape(X.shape[0], -1)\n",
    "\n",
    "# 1. Split test set (5 random subjects, fixed seed)\n",
    "unique_subjects = np.unique(subject_ids)\n",
    "np.random.seed(13)\n",
    "test_subjects = np.random.choice(unique_subjects, size=5, replace=False)\n",
    "np.save(\"test_subjects.npy\", test_subjects)\n",
    "train_subjects = np.setdiff1d(unique_subjects, test_subjects)\n",
    "\n",
    "train_idx = np.where(np.isin(subject_ids, train_subjects))[0]\n",
    "test_idx = np.where(np.isin(subject_ids, test_subjects))[0]\n",
    "\n",
    "X_train = X_combined[train_idx]\n",
    "y_train = y_combined[train_idx]\n",
    "train_subj_ids = subject_ids[train_idx]\n",
    "\n",
    "X_test = X_combined[test_idx]\n",
    "y_test = y_combined[test_idx]\n",
    "\n",
    "outer_loo = LeaveOneOut()\n",
    "inner_subjects = np.unique(train_subj_ids)\n",
    "best_n_bins_per_fold = []\n",
    "best_C_per_fold = []\n",
    "val_accuracies = []\n",
    "val_subject_ids = []\n",
    "\n",
    "for fold_num, (train_sub_idx, val_sub_idx) in enumerate(outer_loo.split(inner_subjects), start=1):\n",
    "    print(f\"Processing fold {fold_num}/{len(inner_subjects)}...\")\n",
    "\n",
    "    inner_train_subj = inner_subjects[train_sub_idx]\n",
    "    val_subj = inner_subjects[val_sub_idx[0]]\n",
    "\n",
    "    inner_train_idx = np.where(np.isin(train_subj_ids, inner_train_subj))[0]\n",
    "    val_idx = np.where(train_subj_ids == val_subj)[0]\n",
    "\n",
    "    X_inner = X_train[inner_train_idx]\n",
    "    y_inner = y_train[inner_train_idx]\n",
    "    X_val = X_train[val_idx]\n",
    "    y_val = y_train[val_idx]\n",
    "\n",
    "    best_score = -np.inf\n",
    "    best_n_bins = None\n",
    "    best_C = None\n",
    "    best_model = None\n",
    "    best_scaler = None\n",
    "\n",
    "    for n_bins in freq_bin_options:\n",
    "        for C in C_grid:\n",
    "            X_inner_binned = reduce_freq_resolution(X_inner, n_bins)\n",
    "            X_val_binned = reduce_freq_resolution(X_val, n_bins)\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            X_inner_scaled = scaler.fit_transform(X_inner_binned)\n",
    "            X_val_scaled = scaler.transform(X_val_binned)\n",
    "\n",
    "            clf = LogisticRegression(C=C, max_iter=1000)\n",
    "            clf.fit(X_inner_scaled, y_inner)\n",
    "            probs = clf.predict_proba(X_val_scaled)\n",
    "            score = -log_loss( y_val,probs)\n",
    "            acc = accuracy_score(y_val, clf.predict(X_val_scaled))\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_n_bins = n_bins\n",
    "                best_C = C\n",
    "                best_model = clf\n",
    "                best_scaler = scaler\n",
    "\n",
    "    preds = best_model.predict(best_scaler.transform(reduce_freq_resolution(X_val, best_n_bins)))\n",
    "    best_n_bins_per_fold.append(best_n_bins)\n",
    "    best_C_per_fold.append(best_C)\n",
    "    val_accuracies.append(acc)\n",
    "    val_subject_ids.append(val_subj)\n",
    "\n",
    "np.save(\"val_accuracies.npy\", np.array(val_accuracies))\n",
    "np.save(\"val_subject_ids.npy\", np.array(val_subject_ids))\n",
    "\n",
    "# Retrain model with best hyperparameters\n",
    "final_n_bins = Counter(best_n_bins_per_fold).most_common(1)[0][0]\n",
    "final_C = Counter(best_C_per_fold).most_common(1)[0][0]\n",
    "\n",
    "X_train_binned = reduce_freq_resolution(X_train, final_n_bins)\n",
    "X_test_binned = reduce_freq_resolution(X_test, final_n_bins)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_binned)\n",
    "X_test_scaled = scaler.transform(X_test_binned)\n",
    "\n",
    "final_model = LogisticRegression(C=final_C, max_iter=1000)\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save model, scaler and bins\n",
    "joblib.dump(final_model, \"final_model_lr.pkl\")\n",
    "joblib.dump(scaler, \"final_scaler_lr.pkl\")\n",
    "np.save(\"final_n_bins_lr.npy\", final_n_bins)\n",
    "\n",
    "# 4. Evaluate on test set\n",
    "y_pred = final_model.predict(X_test_scaled)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a79dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities for class 1 (Eyes Closed)\n",
    "y_proba = final_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr, tpr, color=\"green\", label=f\"Logistic Regression (AUC = {roc_auc:.2f})\", linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - Logistic Regression\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6647c40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", acc)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7528928a",
   "metadata": {},
   "source": [
    "### Plotting the test accuracy for each of the 25 subjcts in the training set during LOSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dfbea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved data\n",
    "val_accuracies = np.load(\"val_accuracies.npy\")\n",
    "val_subject_ids = np.load(\"val_subject_ids.npy\")\n",
    "\n",
    "# Sort by subject ID for better visualization\n",
    "sorted_indices = np.argsort(val_subject_ids)\n",
    "sorted_subjects = val_subject_ids[sorted_indices]\n",
    "sorted_accuracies = val_accuracies[sorted_indices]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(sorted_subjects.astype(str), sorted_accuracies, color=\"#396A48\")\n",
    "plt.title(\"Accuracy per Subject (LOSO) - Logistic Regression\")\n",
    "plt.xlabel(\"Subject ID\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2beb57",
   "metadata": {},
   "source": [
    "## Printing the chosen hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88373209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find de mest brugte v√¶rdier for n_bins og C\n",
    "final_n_bins = Counter(best_n_bins_per_fold).most_common(1)[0][0]\n",
    "final_C = Counter(best_C_per_fold).most_common(1)[0][0]\n",
    "\n",
    "print(\"\\nüéØ Bedste hyperparametre fundet i inner loop:\")\n",
    "print(f\"   - Antal frekvens-bins (n_bins): {final_n_bins}\")\n",
    "print(f\"   - Regulariseringsparameter (C): {final_C}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926d9652",
   "metadata": {},
   "source": [
    "## Plotting accuracy per subject in the hold out set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538a75cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Group predictions by test subject\n",
    "test_subjects_unique = np.unique(subject_ids[test_idx])\n",
    "subject_metrics = []\n",
    "\n",
    "for subj in test_subjects_unique:\n",
    "    subj_mask = subject_ids[test_idx] == subj\n",
    "    y_true_subj = y_test[subj_mask]\n",
    "    y_pred_subj = y_pred[subj_mask]\n",
    "\n",
    "    acc_subj = accuracy_score(y_true_subj, y_pred_subj)\n",
    "    prec_subj = precision_score(y_true_subj, y_pred_subj)\n",
    "    rec_subj = recall_score(y_true_subj, y_pred_subj)\n",
    "\n",
    "    subject_metrics.append({\n",
    "        'subject': subj,\n",
    "        'accuracy': acc_subj,\n",
    "        'precision': prec_subj,\n",
    "        'recall': rec_subj\n",
    "    })\n",
    "\n",
    "# 2. Print metrics per subject\n",
    "print(\"Per-subject performance:\")\n",
    "for metrics in subject_metrics:\n",
    "    print(f\"Subject {metrics['subject']}: \"\n",
    "          f\"Accuracy = {metrics['accuracy']:.2f}, \"\n",
    "          f\"Precision = {metrics['precision']:.2f}, \"\n",
    "          f\"Recall = {metrics['recall']:.2f}\")\n",
    "\n",
    "# 3. Plot accuracy per subject\n",
    "plt.figure(figsize=(8, 5))\n",
    "subject_ids_sorted = [m['subject'] for m in subject_metrics]\n",
    "accuracies = [m['accuracy'] for m in subject_metrics]\n",
    "sns.barplot(x=subject_ids_sorted, y=accuracies, color=\"#54874A\")\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"Accuracy per Test Subject\")\n",
    "plt.xlabel(\"Subject ID\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Combined confusion matrix\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Greens', cbar=False)\n",
    "plt.title(\"Confusion Matrix (All Test Subjects)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7a0308",
   "metadata": {},
   "source": [
    "### Saving predictions and stuff for statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad0757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('y_test.npy', y_test)\n",
    "np.save('y_pred_lr.npy', y_pred)\n",
    "np.save('probs_lr.npy', final_model.predict_proba(X_test_scaled))\n",
    "np.save('subject_ids_test.npy', subject_ids[test_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9d0909",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eca775",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 19\n",
    "n_freqs = X_combined.shape[1] // n_channels\n",
    "\n",
    "# Load test subjects used in logistic regression\n",
    "test_subjects_svm = np.load(\"test_subjects.npy\")\n",
    "train_subjects_svm = np.setdiff1d(np.unique(subject_ids), test_subjects_svm)\n",
    "\n",
    "train_idx_svm = np.where(np.isin(subject_ids, train_subjects_svm))[0]\n",
    "test_idx_svm = np.where(np.isin(subject_ids, test_subjects_svm))[0]\n",
    "\n",
    "X_train_svm = X_combined[train_idx_svm]\n",
    "y_train_svm = y_combined[train_idx_svm]\n",
    "train_subj_ids_svm = subject_ids[train_idx_svm]\n",
    "\n",
    "X_test_svm = X_combined[test_idx_svm]\n",
    "y_test_svm = y_combined[test_idx_svm]\n",
    "\n",
    "# Define parameter grids\n",
    "freq_bin_options_svm = [5]\n",
    "C_grid_svm = [0.01, 0.1, 0.5]\n",
    "\n",
    "def reduce_freq_resolution_svm(X, n_bins):\n",
    "    bin_size = n_freqs // n_bins\n",
    "    X_reshaped = X.reshape(-1, n_channels, n_freqs)\n",
    "    reduced = np.stack([\n",
    "        X_reshaped[:, :, i * bin_size:(i + 1) * bin_size].mean(axis=2)\n",
    "        for i in range(n_bins)\n",
    "    ], axis=2)\n",
    "    return reduced.reshape(X.shape[0], -1)\n",
    "\n",
    "# Nested LOSO CV on training set\n",
    "outer_loo_svm = LeaveOneOut()\n",
    "inner_subjects_svm = np.unique(train_subj_ids_svm)\n",
    "best_n_bins_per_fold_svm = []\n",
    "best_C_per_fold_svm = []\n",
    "val_accuracies_svm = []\n",
    "val_subject_ids_svm = []\n",
    "\n",
    "for i, (train_sub_idx, val_sub_idx) in enumerate(outer_loo_svm.split(inner_subjects_svm), 1):\n",
    "    print(f\"SVM Fold {i}/{len(inner_subjects_svm)}\")\n",
    "\n",
    "    inner_train_subj_svm = inner_subjects_svm[train_sub_idx]\n",
    "    val_subj_svm = inner_subjects_svm[val_sub_idx[0]]\n",
    "\n",
    "    inner_train_idx_svm = np.where(np.isin(train_subj_ids_svm, inner_train_subj_svm))[0]\n",
    "    val_idx_svm = np.where(train_subj_ids_svm == val_subj_svm)[0]\n",
    "\n",
    "    X_inner_svm = X_train_svm[inner_train_idx_svm]\n",
    "    y_inner_svm = y_train_svm[inner_train_idx_svm]\n",
    "    X_val_svm = X_train_svm[val_idx_svm]\n",
    "    y_val_svm = y_train_svm[val_idx_svm]\n",
    "\n",
    "    best_score_svm = -np.inf\n",
    "    best_n_bins_svm = None\n",
    "    best_C_svm = None\n",
    "\n",
    "    for n_bins in freq_bin_options_svm:\n",
    "        for C in C_grid_svm:\n",
    "            X_inner_binned_svm = reduce_freq_resolution_svm(X_inner_svm, n_bins)\n",
    "            X_val_binned_svm = reduce_freq_resolution_svm(X_val_svm, n_bins)\n",
    "\n",
    "            scaler_svm = StandardScaler()\n",
    "            X_inner_scaled_svm = scaler_svm.fit_transform(X_inner_binned_svm)\n",
    "            X_val_scaled_svm = scaler_svm.transform(X_val_binned_svm)\n",
    "\n",
    "            clf_svm = SVC(C=C, kernel='linear', probability=True)\n",
    "            clf_svm.fit(X_inner_scaled_svm, y_inner_svm)\n",
    "            probs = clf_svm.predict_proba(X_val_scaled_svm)\n",
    "            score = -log_loss(y_val_svm, probs)\n",
    "            acc = accuracy_score(y_val_svm, clf_svm.predict(X_val_scaled_svm))\n",
    "\n",
    "            if score > best_score_svm:\n",
    "                best_score_svm = score\n",
    "                best_n_bins_svm = n_bins\n",
    "                best_C_svm = C\n",
    "    \n",
    "    best_n_bins_per_fold_svm.append(best_n_bins_svm)\n",
    "    best_C_per_fold_svm.append(best_C_svm)\n",
    "    val_accuracies_svm.append(acc)\n",
    "    val_subject_ids_svm.append(val_subj_svm)\n",
    "\n",
    "# Save per-subject validation accuracy\n",
    "np.save(\"val_svm_accuracies.npy\", np.array(val_accuracies_svm))\n",
    "np.save(\"val_svm_subject_ids.npy\", np.array(val_subject_ids_svm))\n",
    "\n",
    "# Train final model\n",
    "final_n_bins_svm = Counter(best_n_bins_per_fold_svm).most_common(1)[0][0]\n",
    "final_C_svm = Counter(best_C_per_fold_svm).most_common(1)[0][0]\n",
    "\n",
    "X_train_binned_svm = reduce_freq_resolution_svm(X_train_svm, final_n_bins_svm)\n",
    "X_test_binned_svm = reduce_freq_resolution_svm(X_test_svm, final_n_bins_svm)\n",
    "\n",
    "scaler_final_svm = StandardScaler()\n",
    "X_train_scaled_svm = scaler_final_svm.fit_transform(X_train_binned_svm)\n",
    "X_test_scaled_svm = scaler_final_svm.transform(X_test_binned_svm)\n",
    "\n",
    "final_model_svm = SVC(C=final_C_svm, kernel='linear', probability=True)\n",
    "final_model_svm.fit(X_train_scaled_svm, y_train_svm)\n",
    "\n",
    "# Save model and scaler\n",
    "joblib.dump(final_model_svm, \"final_model_svm.pkl\")\n",
    "joblib.dump(scaler_final_svm, \"final_scaler_svm.pkl\")\n",
    "np.save(\"final_n_bins_svm.npy\", final_n_bins_svm)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_svm = final_model_svm.predict(X_test_scaled_svm)\n",
    "acc_svm = accuracy_score(y_test_svm, y_pred_svm)\n",
    "report_svm = classification_report(y_test_svm, y_pred_svm)\n",
    "conf_matrix_svm = confusion_matrix(y_test_svm, y_pred_svm)\n",
    "y_proba_svm = final_model_svm.predict_proba(X_test_scaled_svm)\n",
    "loss_svm = log_loss(y_test_svm, y_proba_svm)\n",
    "\n",
    "print(\"SVM Accuracy:\", acc_svm)\n",
    "print(\"SVM Log Loss:\", loss_svm)\n",
    "print(\"SVM Classification Report:\\n\", report_svm)\n",
    "print(\"SVM Confusion Matrix:\\n\", conf_matrix_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69423300",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", acc_svm)\n",
    "print(\"Classification Report:\\n\", report_svm)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7fb701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities for class 1 (Eyes Closed)\n",
    "y_proba_svm_class1 = y_proba_svm[:, 1]\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, _ = roc_curve(y_test_svm, y_proba_svm_class1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr, tpr, color=\"green\", label=f\"SVM (AUC = {roc_auc:.2f})\", linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - SVM\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c48e47",
   "metadata": {},
   "source": [
    "# Accuracies of the 25 test subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709bd8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved accuracies and subject IDs\n",
    "val_accuracies = np.load(\"val_svm_accuracies.npy\")\n",
    "val_subject_ids = np.load(\"val_svm_subject_ids.npy\")\n",
    "\n",
    "# Sort by subject ID for a cleaner plot\n",
    "sorted_indices = np.argsort(val_subject_ids)\n",
    "val_subject_ids = val_subject_ids[sorted_indices]\n",
    "val_accuracies = val_accuracies[sorted_indices]\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar([str(sid) for sid in val_subject_ids], val_accuracies, color=\"#396A48\")\n",
    "plt.xlabel(\"Subject ID\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy per Subject (LOSO) - SVM\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a008d5",
   "metadata": {},
   "source": [
    "## Print hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c98dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_n_bins_svm = Counter(best_n_bins_per_fold_svm).most_common(1)[0][0]\n",
    "final_C_svm = Counter(best_C_per_fold_svm).most_common(1)[0][0]\n",
    "\n",
    "print(\"\\n Bedste hyperparametre fundet i SVM (inner loop):\")\n",
    "print(f\"   - Antal frekvens-bins (n_bins): {final_n_bins_svm}\")\n",
    "print(f\"   - Regulariseringsparameter (C): {final_C_svm}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade3b330",
   "metadata": {},
   "source": [
    "## Subject wise analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7914773f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Group predictions by SVM test subject\n",
    "test_subjects_unique_svm = np.unique(subject_ids[test_idx_svm])\n",
    "subject_metrics_svm = []\n",
    "\n",
    "for subj in test_subjects_unique_svm:\n",
    "    subj_mask = subject_ids[test_idx_svm] == subj\n",
    "    y_true_subj = y_test_svm[subj_mask]\n",
    "    y_pred_subj = y_pred_svm[subj_mask]\n",
    "\n",
    "    acc_subj = accuracy_score(y_true_subj, y_pred_subj)\n",
    "    prec_subj = precision_score(y_true_subj, y_pred_subj, zero_division=0)\n",
    "    rec_subj = recall_score(y_true_subj, y_pred_subj, zero_division=0)\n",
    "\n",
    "    subject_metrics_svm.append({\n",
    "        'subject': subj,\n",
    "        'accuracy': acc_subj,\n",
    "        'precision': prec_subj,\n",
    "        'recall': rec_subj\n",
    "    })\n",
    "\n",
    "# 2. Print SVM metrics per subject\n",
    "print(\"üìä Per-subject performance (SVM):\")\n",
    "for metrics in subject_metrics_svm:\n",
    "    print(f\"Subject {metrics['subject']}: \"\n",
    "          f\"Accuracy = {metrics['accuracy']:.2f}, \"\n",
    "          f\"Precision = {metrics['precision']:.2f}, \"\n",
    "          f\"Recall = {metrics['recall']:.2f}\")\n",
    "\n",
    "# 3. Plot accuracy per subject (SVM)\n",
    "plt.figure(figsize=(8, 5))\n",
    "subject_ids_sorted_svm = [m['subject'] for m in subject_metrics_svm]\n",
    "accuracies_svm = [m['accuracy'] for m in subject_metrics_svm]\n",
    "sns.barplot(x=subject_ids_sorted_svm, y=accuracies_svm, color=\"#54874A\")\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"Accuracy per Test Subject - SVM\")\n",
    "plt.xlabel(\"Subject ID\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Combined confusion matrix (SVM)\n",
    "conf_matrix_svm = confusion_matrix(y_test_svm, y_pred_svm)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(conf_matrix_svm, annot=True, fmt='d', cmap='Greens', cbar=False,\n",
    "            xticklabels=[\"Eyes Open\", \"Eyes Closed\"],\n",
    "            yticklabels=[\"Eyes Open\", \"Eyes Closed\"])\n",
    "plt.title(\"Confusion Matrix - SVM (All Test Subjects)\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d4dd90",
   "metadata": {},
   "source": [
    "### Saving files for statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d92f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('y_pred_svm.npy', y_pred_svm)\n",
    "np.save('probs_svm.npy', y_proba_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bece7e",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b37974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume X_combined, y_combined, subject_ids are already defined\n",
    "n_channels = 19\n",
    "n_freqs = X_combined.shape[1] // n_channels\n",
    "\n",
    "# Load fixed test subjects\n",
    "test_subjects_rf = np.load(\"test_subjects.npy\")\n",
    "train_subjects_rf = np.setdiff1d(np.unique(subject_ids), test_subjects_rf)\n",
    "\n",
    "train_idx_rf = np.where(np.isin(subject_ids, train_subjects_rf))[0]\n",
    "test_idx_rf = np.where(np.isin(subject_ids, test_subjects_rf))[0]\n",
    "\n",
    "X_train_rf = X_combined[train_idx_rf]\n",
    "y_train_rf = y_combined[train_idx_rf]\n",
    "train_subj_ids_rf = subject_ids[train_idx_rf]\n",
    "\n",
    "X_test_rf = X_combined[test_idx_rf]\n",
    "y_test_rf = y_combined[test_idx_rf]\n",
    "\n",
    "# Hyperparameter grids\n",
    "freq_bin_options_rf = [5]\n",
    "n_estimators_grid_rf = [100, 150]\n",
    "max_depth_grid_rf = [None, 10, 20]\n",
    "\n",
    "def reduce_freq_resolution_rf(X, n_bins):\n",
    "    bin_size = n_freqs // n_bins\n",
    "    X_reshaped = X.reshape(-1, n_channels, n_freqs)\n",
    "    reduced = np.stack([\n",
    "        X_reshaped[:, :, i * bin_size:(i + 1) * bin_size].mean(axis=2)\n",
    "        for i in range(n_bins)\n",
    "    ], axis=2)\n",
    "    return reduced.reshape(X.shape[0], -1)\n",
    "\n",
    "# Nested LOSO\n",
    "outer_loo_rf = LeaveOneOut()\n",
    "inner_subjects_rf = np.unique(train_subj_ids_rf)\n",
    "best_n_bins_per_fold_rf = []\n",
    "best_n_estimators_per_fold_rf = []\n",
    "best_max_depth_per_fold_rf = []\n",
    "val_accuracies_rf = []\n",
    "val_log_losses_rf = []\n",
    "val_subject_ids_rf = []\n",
    "\n",
    "for i, (train_sub_idx, val_sub_idx) in enumerate(outer_loo_rf.split(inner_subjects_rf), 1):\n",
    "    print(f\"RF Fold {i}/{len(inner_subjects_rf)}\")\n",
    "\n",
    "    inner_train_subj = inner_subjects_rf[train_sub_idx]\n",
    "    val_subj = inner_subjects_rf[val_sub_idx[0]]\n",
    "\n",
    "    inner_train_idx = np.where(np.isin(train_subj_ids_rf, inner_train_subj))[0]\n",
    "    val_idx = np.where(train_subj_ids_rf == val_subj)[0]\n",
    "\n",
    "    X_inner = X_train_rf[inner_train_idx]\n",
    "    y_inner = y_train_rf[inner_train_idx]\n",
    "    X_val = X_train_rf[val_idx]\n",
    "    y_val = y_train_rf[val_idx]\n",
    "\n",
    "    best_score = -np.inf\n",
    "    best_n_bins = None\n",
    "    best_n_estimators = None\n",
    "    best_max_depth = None\n",
    "    best_acc = None\n",
    "    best_loss = None\n",
    "\n",
    "    for n_bins in freq_bin_options_rf:\n",
    "        for n_estimators in n_estimators_grid_rf:\n",
    "            for max_depth in max_depth_grid_rf:\n",
    "                X_inner_binned = reduce_freq_resolution_rf(X_inner, n_bins)\n",
    "                X_val_binned = reduce_freq_resolution_rf(X_val, n_bins)\n",
    "\n",
    "                scaler = StandardScaler()\n",
    "                X_inner_scaled = scaler.fit_transform(X_inner_binned)\n",
    "                X_val_scaled = scaler.transform(X_val_binned)\n",
    "\n",
    "                clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=13)\n",
    "                clf.fit(X_inner_scaled, y_inner)\n",
    "                proba = clf.predict_proba(X_val_scaled)\n",
    "                score = -log_loss(y_val, proba)\n",
    "                acc = accuracy_score(y_val, clf.predict(X_val_scaled))\n",
    "\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_n_bins = n_bins\n",
    "                    best_n_estimators = n_estimators\n",
    "                    best_max_depth = max_depth\n",
    "                    best_acc = acc\n",
    "                    best_loss = score\n",
    "\n",
    "    best_n_bins_per_fold_rf.append(best_n_bins)\n",
    "    best_n_estimators_per_fold_rf.append(best_n_estimators)\n",
    "    best_max_depth_per_fold_rf.append(best_max_depth)\n",
    "    val_accuracies_rf.append(best_acc)\n",
    "    val_log_losses_rf.append(best_loss)\n",
    "    val_subject_ids_rf.append(val_subj)\n",
    "\n",
    "# Save validation results\n",
    "np.save(\"rf_val_accuracies.npy\", np.array(val_accuracies_rf))\n",
    "np.save(\"rf_val_log_losses.npy\", np.array(val_log_losses_rf))\n",
    "np.save(\"rf_val_subject_ids.npy\", np.array(val_subject_ids_rf))\n",
    "\n",
    "# Train final model\n",
    "final_n_bins_rf = Counter(best_n_bins_per_fold_rf).most_common(1)[0][0]\n",
    "final_n_estimators_rf = Counter(best_n_estimators_per_fold_rf).most_common(1)[0][0]\n",
    "final_max_depth_rf = Counter(best_max_depth_per_fold_rf).most_common(1)[0][0]\n",
    "\n",
    "X_train_binned_rf = reduce_freq_resolution_rf(X_train_rf, final_n_bins_rf)\n",
    "X_test_binned_rf = reduce_freq_resolution_rf(X_test_rf, final_n_bins_rf)\n",
    "\n",
    "scaler_rf = StandardScaler()\n",
    "X_train_scaled_rf = scaler_rf.fit_transform(X_train_binned_rf)\n",
    "X_test_scaled_rf = scaler_rf.transform(X_test_binned_rf)\n",
    "\n",
    "final_model_rf = RandomForestClassifier(\n",
    "    n_estimators=final_n_estimators_rf,\n",
    "    max_depth=final_max_depth_rf,\n",
    "    random_state=42\n",
    ")\n",
    "final_model_rf.fit(X_train_scaled_rf, y_train_rf)\n",
    "\n",
    "# Save final model\n",
    "joblib.dump(final_model_rf, \"final_model_rf.pkl\")\n",
    "joblib.dump(scaler_rf, \"final_scaler_rf.pkl\")\n",
    "np.save(\"final_n_bins_rf.npy\", final_n_bins_rf)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_rf = final_model_rf.predict(X_test_scaled_rf)\n",
    "acc_rf = accuracy_score(y_test_rf, y_pred_rf)\n",
    "y_proba_rf = final_model_rf.predict_proba(X_test_scaled_rf)\n",
    "loss_rf = log_loss(y_test_rf, y_proba_rf)\n",
    "report_rf = classification_report(y_test_rf, y_pred_rf)\n",
    "conf_matrix_rf = confusion_matrix(y_test_rf, y_pred_rf)\n",
    "\n",
    "print(\"RF Accuracy:\", acc_rf)\n",
    "print(\"RF Log Loss:\", loss_rf)\n",
    "print(\"RF Classification Report:\\n\", report_rf)\n",
    "print(\"RF Confusion Matrix:\\n\", conf_matrix_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fa0fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", acc_rf)\n",
    "print(\"Log loss:\", loss_rf)\n",
    "print(\"Classification Report:\\n\", report_rf)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b2015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probabilities for class 1 (Eyes Closed)\n",
    "y_proba_rf_class1 = y_proba_rf[:, 1]\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test_rf, y_proba_rf_class1)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr_rf, tpr_rf, color=\"green\", label=f\"Random Forest (AUC = {roc_auc_rf:.2f})\", linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - Random Forest\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b1a6b9",
   "metadata": {},
   "source": [
    "# Accuracies of the 25 subjects in LOSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0284a8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved per-subject accuracies and IDs\n",
    "val_accuracies = np.load(\"rf_val_accuracies.npy\")\n",
    "val_subject_ids = np.load(\"rf_val_subject_ids.npy\")\n",
    "\n",
    "# Sort by subject ID for better readability\n",
    "sorted_indices = np.argsort(val_subject_ids)\n",
    "sorted_subjects = val_subject_ids[sorted_indices]\n",
    "sorted_accuracies = val_accuracies[sorted_indices]\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar([str(subj) for subj in sorted_subjects], sorted_accuracies, color=\"#396A48\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Subject ID\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy per Subject (LOSO) - Random Forest\")\n",
    "plt.tight_layout()\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707d53d7",
   "metadata": {},
   "source": [
    "## Print hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986055ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find de mest brugte v√¶rdier for n_bins, n_estimators og max_depth i RF\n",
    "final_n_bins_rf = Counter(best_n_bins_per_fold_rf).most_common(1)[0][0]\n",
    "final_n_estimators_rf = Counter(best_n_estimators_per_fold_rf).most_common(1)[0][0]\n",
    "final_max_depth_rf = Counter(best_max_depth_per_fold_rf).most_common(1)[0][0]\n",
    "\n",
    "print(\"\\n Bedste hyperparametre fundet i Random Forest (inner loop):\")\n",
    "print(f\"   - Antal frekvens-bins (n_bins): {final_n_bins_rf}\")\n",
    "print(f\"   - Antal tr√¶er (n_estimators): {final_n_estimators_rf}\")\n",
    "print(f\"   - Maks dybde p√• tr√¶er (max_depth): {final_max_depth_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3f68a4",
   "metadata": {},
   "source": [
    "## Analysis of subjects in hold out set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05b43b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Group predictions by RF test subject\n",
    "test_subjects_unique_rf = np.unique(subject_ids[test_idx_rf])\n",
    "subject_metrics_rf = []\n",
    "\n",
    "for subj in test_subjects_unique_rf:\n",
    "    subj_mask = subject_ids[test_idx_rf] == subj\n",
    "    y_true_subj = y_test_rf[subj_mask]\n",
    "    y_pred_subj = y_pred_rf[subj_mask]\n",
    "\n",
    "    acc_subj = accuracy_score(y_true_subj, y_pred_subj)\n",
    "    prec_subj = precision_score(y_true_subj, y_pred_subj, zero_division=0)\n",
    "    rec_subj = recall_score(y_true_subj, y_pred_subj, zero_division=0)\n",
    "\n",
    "    subject_metrics_rf.append({\n",
    "        'subject': subj,\n",
    "        'accuracy': acc_subj,\n",
    "        'precision': prec_subj,\n",
    "        'recall': rec_subj\n",
    "    })\n",
    "\n",
    "# 2. Print RF metrics per subject\n",
    "print(\"üìä Per-subject performance (Random Forest):\")\n",
    "for metrics in subject_metrics_rf:\n",
    "    print(f\"Subject {metrics['subject']}: \"\n",
    "          f\"Accuracy = {metrics['accuracy']:.2f}, \"\n",
    "          f\"Precision = {metrics['precision']:.2f}, \"\n",
    "          f\"Recall = {metrics['recall']:.2f}\")\n",
    "\n",
    "# 3. Plot accuracy per subject (RF)\n",
    "plt.figure(figsize=(8, 5))\n",
    "subject_ids_sorted_rf = [m['subject'] for m in subject_metrics_rf]\n",
    "accuracies_rf = [m['accuracy'] for m in subject_metrics_rf]\n",
    "sns.barplot(x=subject_ids_sorted_rf, y=accuracies_rf, color=\"#54874A\")\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"Accuracy per Test Subject - Random Forest\")\n",
    "plt.xlabel(\"Subject ID\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Combined confusion matrix (RF)\n",
    "conf_matrix_rf = confusion_matrix(y_test_rf, y_pred_rf)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(conf_matrix_rf, annot=True, fmt='d', cmap='Greens', cbar=False,\n",
    "            xticklabels=[\"Eyes Open\", \"Eyes Closed\"],\n",
    "            yticklabels=[\"Eyes Open\", \"Eyes Closed\"])\n",
    "plt.title(\"Confusion Matrix - Random Forest (All Test Subjects)\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e30663",
   "metadata": {},
   "source": [
    "### Saving files for statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2557a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('y_pred_rf.npy', y_pred_rf)\n",
    "np.save('probs_rf.npy', y_proba_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6733286c",
   "metadata": {},
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd14bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Feature reduction functions ---\n",
    "def reduce_freq_resolution(X, n_channels, n_freqs, n_bins):\n",
    "    bin_size = n_freqs // n_bins\n",
    "    X_reshaped = X.reshape(-1, n_channels, n_freqs)\n",
    "    reduced = np.stack([\n",
    "        X_reshaped[:, :, i * bin_size:(i + 1) * bin_size].mean(axis=2)\n",
    "        for i in range(n_bins)\n",
    "    ], axis=2)\n",
    "    return reduced.reshape(X.shape[0], -1)\n",
    "\n",
    "# --- Load models and preprocessing ---\n",
    "# Logistic Regression\n",
    "lr_model = joblib.load(\"final_model_lr.pkl\")\n",
    "lr_scaler = joblib.load(\"final_scaler_lr.pkl\")\n",
    "lr_n_bins = int(np.load(\"final_n_bins_lr.npy\"))\n",
    "\n",
    "# SVM\n",
    "svm_model = joblib.load(\"final_model_svm.pkl\")\n",
    "svm_scaler = joblib.load(\"final_scaler_svm.pkl\")\n",
    "svm_n_bins = int(np.load(\"final_n_bins_svm.npy\"))\n",
    "\n",
    "# Random Forest\n",
    "rf_model = joblib.load(\"final_model_rf.pkl\")\n",
    "rf_scaler = joblib.load(\"final_scaler_rf.pkl\")\n",
    "rf_n_bins = int(np.load(\"final_n_bins_rf.npy\"))\n",
    "\n",
    "# --- Settings (update these for your data!) ---\n",
    "n_channels = 19\n",
    "n_freqs = X_combined.shape[1] // n_channels  # Or set to whatever matches your features\n",
    "\n",
    "# --- Predict on new data (X_new) ---\n",
    "def get_model_proba(model, scaler, n_bins, X, n_channels, n_freqs):\n",
    "    X_binned = reduce_freq_resolution(X, n_channels, n_freqs, n_bins)\n",
    "    X_scaled = scaler.transform(X_binned)\n",
    "    probs = model.predict_proba(X_scaled)\n",
    "    return probs\n",
    "\n",
    "# Example: Predict on test set\n",
    "X_ensemble = X_test_rf  # Or any data of shape (samples, features)\n",
    "\n",
    "probs_lr = get_model_proba(lr_model, lr_scaler, lr_n_bins, X_ensemble, n_channels, n_freqs)\n",
    "probs_svm = get_model_proba(svm_model, svm_scaler, svm_n_bins, X_ensemble, n_channels, n_freqs)\n",
    "probs_rf = get_model_proba(rf_model, rf_scaler, rf_n_bins, X_ensemble, n_channels, n_freqs)\n",
    "\n",
    "# --- Soft Voting Ensemble (average probabilities) ---\n",
    "ensemble_probs = (probs_lr + probs_svm + probs_rf) / 3\n",
    "ensemble_pred = np.argmax(ensemble_probs, axis=1)  # Class labels\n",
    "\n",
    "# --- Evaluate ---\n",
    "\n",
    "print(\"Ensemble Accuracy:\", accuracy_score(y_test_rf, ensemble_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_rf, ensemble_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_rf, ensemble_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed962d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inputs (from your code context) ---\n",
    "# y_test_rf: true labels for the RF test set\n",
    "# ensemble_pred: predictions from the ensemble\n",
    "# subject_ids_test: array of subject IDs matching y_test_rf\n",
    "\n",
    "# --- Compute accuracy per subject ---\n",
    "subject_ids_test = np.load(\"subject_ids_test.npy\")\n",
    "subject_accuracies = []\n",
    "unique_subjects = np.unique(subject_ids_test)\n",
    "\n",
    "for subj in unique_subjects:\n",
    "    subj_mask = subject_ids_test == subj\n",
    "    acc = accuracy_score(y_test_rf[subj_mask], ensemble_pred[subj_mask])\n",
    "    subject_accuracies.append({'Subject': subj, 'Accuracy': acc})\n",
    "\n",
    "# --- Convert to DataFrame ---\n",
    "df_acc = pd.DataFrame(subject_accuracies)\n",
    "\n",
    "# --- Plot ---\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=df_acc, x=\"Subject\", y=\"Accuracy\", color=\"#54874A\")\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"Accuracy per Test Subject ‚Äì Model Ensemble\")\n",
    "plt.xlabel(\"Subject ID\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6d6de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Confusion Matrix for Ensemble Model ---\n",
    "conf_matrix_ensemble = confusion_matrix(y_test_rf, ensemble_pred)\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(conf_matrix_ensemble, annot=True, fmt='d', cmap='Greens', cbar=False,\n",
    "            xticklabels=[\"Eyes Open\", \"Eyes Closed\"],\n",
    "            yticklabels=[\"Eyes Open\", \"Eyes Closed\"])\n",
    "plt.title(\"Confusion Matrix - Model Ensemble (All Test Subjects)\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e83c575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and AUC for class 1 (Eyes Closed)\n",
    "fpr, tpr, _ = roc_curve(y_test_rf, ensemble_probs[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr, tpr, color=\"green\", label=f\"Ensemble (AUC = {roc_auc:.2f})\", linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - Model Ensemble\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
